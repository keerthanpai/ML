{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification: Instant Recognition with Caffe\n",
    "\n",
    "In this example we'll classify an image with the bundled CaffeNet model (which is based on the network architecture of Krizhevsky et al. for ImageNet).\n",
    "\n",
    "We'll compare CPU and GPU modes and then dig into the model to inspect features and the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup\n",
    "\n",
    "* First, set up Python, `numpy`, and `matplotlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set up Python environment: numpy for numerical routines, and matplotlib for plotting\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob2 \n",
    "import string\n",
    "# display plots in this notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# set display defaults\n",
    "plt.rcParams['figure.figsize'] = (10, 10)        # large images\n",
    "plt.rcParams['image.interpolation'] = 'nearest'  # don't interpolate: show square pixels\n",
    "plt.rcParams['image.cmap'] = 'gray'  # use grayscale output rather than a (potentially misleading) color heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Load `caffe`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named _caffe",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-85d2a71bdea9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaffe_root\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcaffe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m# If you get \"No module named _caffe\", either you have not built pycaffe or you have the wrong path.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/keerthanpai/caffe/python/caffe/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpycaffe\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSGDSolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNesterovSolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAdaGradSolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRMSPropSolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAdaDeltaSolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAdamSolver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_caffe\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mset_mode_cpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_mode_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_solver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_type_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_random_seed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_caffe\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaffe_pb2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTEST\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/keerthanpai/caffe/python/caffe/pycaffe.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_caffe\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSGDSolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNesterovSolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAdaGradSolver\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mRMSPropSolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAdaDeltaSolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAdamSolver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcaffe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named _caffe"
     ]
    }
   ],
   "source": [
    "# The caffe module needs to be on the Python path;\n",
    "#  we'll add it here explicitly.\n",
    "import sys\n",
    "caffe_root = '../'  # this file should be run from {caffe_root}/examples (otherwise change this line)\n",
    "sys.path.insert(0, caffe_root + 'python')\n",
    "\n",
    "import caffe\n",
    "# If you get \"No module named _caffe\", either you have not built pycaffe or you have the wrong path."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If needed, download the reference model (\"CaffeNet\", a variant of AlexNet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading pre-trained CaffeNet model...\n",
      "/bin/sh: 1: ../scripts/download_model_binary.py: not found\r\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if os.path.isfile(caffe_root + 'models/vggsms/vgg_siamese.caffemodel'):\n",
    "    print 'CaffeNet found.'\n",
    "else:\n",
    "    print 'Downloading pre-trained CaffeNet model...'\n",
    "    !../scripts/download_model_binary.py ../models/vggsms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load net and set up input preprocessing\n",
    "\n",
    "* Set Caffe to CPU mode and load the net from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "caffe.set_mode_cpu()\n",
    "\n",
    "model_def = caffe_root + 'models/vggsms/deploy.prototxt'\n",
    "model_weights = caffe_root + 'models/vggsms/vgg_siamese.caffemodel'\n",
    "\n",
    "net = caffe.Net(model_def,      # defines the structure of the model\n",
    "                model_weights,  # contains the trained weights\n",
    "                caffe.TEST)     # use test mode (e.g., don't perform dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Set up input preprocessing. (We'll use Caffe's `caffe.io.Transformer` to do this, but this step is independent of other parts of Caffe, so any custom preprocessing code may be used).\n",
    "\n",
    "    Our default CaffeNet is configured to take images in BGR format. Values are expected to start in the range [0, 255] and then have the mean ImageNet pixel value subtracted from them. In addition, the channel dimension is expected as the first (_outermost_) dimension.\n",
    "    \n",
    "    As matplotlib will load images with values in the range [0, 1] in RGB format with the channel as the _innermost_ dimension, we are arranging for the needed transformations here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. CPU classification\n",
    "\n",
    "* Now we're ready to perform classification. Even though we'll only classify one image, we'll set a batch size of 50 to demonstrate batching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import PIL\n",
    "from PIL import Image\n",
    "\n",
    "def getFeatures(single_image_pair_with_label):\n",
    "    img1 = Image.open(single_image_pair_with_label[0])\n",
    "    img1=img1.resize((224,224),PIL.Image.ANTIALIAS)\n",
    "    img1=np.uint8(img1)\n",
    "    img1= img1[:, :, (2, 1, 0)]\n",
    "    img1 = img1.transpose((2, 0, 1))\n",
    "\n",
    "    img2 = np.uint8(Image.open(single_image_pair_with_label[1]).resize((224,224),PIL.Image.ANTIALIAS))\n",
    "    img2= img2[:, :, (2, 1, 0)]\n",
    "    img2 = img2.transpose((2, 0, 1))\n",
    "\n",
    "    img3 = np.concatenate((img1,img2))\n",
    "    img3 = img3;\n",
    "\n",
    "    datum = caffe.io.array_to_datum(img3)  \n",
    "\n",
    "    #print img1.shape\n",
    "    #print img2.shape\n",
    "    #print img3.shape\n",
    "    #print {'data': net.blobs['data'].data.shape}\n",
    "\n",
    "    # create transformer for the input called 'data'\n",
    "    transformer = caffe.io.Transformer({'data': net.blobs['data'].data.shape})\n",
    "\n",
    "    transformer.set_transpose('data', (2,0,1))  # move image channels to outermost dimension\n",
    "    #transformer.set_mean('data', mu)            # subtract the dataset-mean value in each channel\n",
    "    transformer.set_raw_scale('data', 255)      # rescale from [0, 1] to [0, 255]\n",
    "    transformer.set_channel_swap('data', (5,4,3,2,1,0))  # swap channels from RGB to BGR\n",
    "\n",
    "    # set the size of the input (we can skip this if we're happy\n",
    "    #  with the default; we can also change it later, e.g., for different batch sizes)\n",
    "    net.blobs['data'].reshape(1,          # batch size\n",
    "                              6,         # 3-channel (BGR) images\n",
    "                              224, 224)  # image size is 227x227\n",
    "\n",
    "    # Load an image (that comes with Caffe) and perform the preprocessing we've set up.\n",
    "\n",
    "    #image = caffe.io.load_image(caffe_root + 'examples/images/cat.jpg')\n",
    "    #transformer = caffe.io.Transformer({'data': net.blobs['data'].data.shape})\n",
    "    transformed_image = transformer.preprocess('data', img3)\n",
    "    #plt.imshow(img3)\n",
    "\n",
    "    # Adorable! Let's classify it!\n",
    "\n",
    "    # copy the image data into the memory allocated for the net\n",
    "    net.blobs['data'].data[...] = transformed_image\n",
    "\n",
    "    ### perform classification\n",
    "    output = net.forward()\n",
    "\n",
    "    output_prob = output['diff'][0]  # the output probability vector for the first image in the batch\n",
    "\n",
    "    #print output_prob\n",
    "    #print 'predicted class is:', output_prob.argmax()\n",
    "    #print len(output_prob)\n",
    "    \n",
    "    return list(output_prob)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'15_1_2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-57c06c1f2eb6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtext_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/home/keerthanpai/Downloads/ML/sample_pics/train_pairlist.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mimage_pairs_with_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpairwiseLabelImages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-73025bf568a7>\u001b[0m in \u001b[0;36mpairwiseLabelImages\u001b[0;34m(image_folder, text_labels_path)\u001b[0m\n\u001b[1;32m     44\u001b[0m                     \u001b[0mgroup_A_B\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                     \u001b[0;31m#image_pairs_with_label.append( [key+'-'+items[i], key+'-'+items[j], [labelmap[group_A_B][1], labelmap[group_A_B][2]] ] )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m                     \u001b[0mimage_pairs_with_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mimage_folder\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_folder\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlabelmap\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgroup_A_B\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabelmap\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgroup_A_B\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;31m#for i in image_pairs_with_label:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '15_1_2'"
     ]
    }
   ],
   "source": [
    "image_folder = '/home/keerthanpai/Downloads/ML/sample_pics/'\n",
    "text_labels = '/home/keerthanpai/Downloads/ML/sample_pics/train_pairlist.txt'\n",
    "\n",
    "image_pairs_with_label = pairwiseLabelImages(image_folder, text_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pairs :  0\n",
      "Number of two way pairs :  0\n"
     ]
    }
   ],
   "source": [
    "two_way_image_pairs_with_label = []\n",
    "for i in image_pairs_with_label:\n",
    "    #print i[0], i[1], [i[2][0], i[2][1]] \n",
    "    two_way_image_pairs_with_label.append( [i[0], i[1], [i[2][0], i[2][1]] ] )\n",
    "    two_way_image_pairs_with_label.append( [i[1], i[0], [i[2][1], i[2][0]] ] )\n",
    "    \n",
    "print \"Number of pairs : \", len(image_pairs_with_label)\n",
    "print \"Number of two way pairs : \", len(two_way_image_pairs_with_label)\n",
    "\n",
    "#for i in two_way_image_pairs_with_label:\n",
    "#    print i[0], i[1], [i[2][0], i[2][1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop 0 of  652 with time 8.42236399651\n",
      "loop 1 of  652 with time 6.79261994362\n",
      "loop 2 of  652 with time 6.51142501831\n",
      "loop 3 of  652 with time 6.48726296425\n",
      "loop 4 of  652 with time 6.50293302536\n",
      "loop 5 of  652 with time 6.73610687256\n",
      "loop 6 of  652 with time 6.46365499496\n",
      "loop 7 of  652 with time 6.53156900406\n",
      "loop 8 of  652 with time 6.47462511063\n",
      "loop 9 of  652 with time 6.64917302132\n",
      "loop 10 of  652 with time 6.59941911697\n",
      "loop 11 of  652 with time 6.62152385712\n",
      "loop 12 of  652 with time 6.48993611336\n",
      "loop 13 of  652 with time 7.03695297241\n",
      "loop 14 of  652 with time 7.1487929821\n",
      "loop 15 of  652 with time 6.60995697975\n",
      "loop 16 of  652 with time 6.77523803711\n",
      "loop 17 of  652 with time 6.97912883759\n",
      "loop 18 of  652 with time 6.92553114891\n",
      "loop 19 of  652 with time 6.62151312828\n",
      "loop 20 of  652 with time 6.91814994812\n",
      "loop 21 of  652 with time 6.61112618446\n",
      "loop 22 of  652 with time 6.9265499115\n",
      "loop 23 of  652 with time 6.5750310421\n",
      "loop 24 of  652 with time 6.76061797142\n",
      "loop 25 of  652 with time 6.86999607086\n",
      "loop 26 of  652 with time 6.853910923\n",
      "loop 27 of  652 with time 6.48507404327\n",
      "loop 28 of  652 with time 6.5105099678\n",
      "loop 29 of  652 with time 6.44763898849\n",
      "loop 30 of  652 with time 6.3772778511\n",
      "loop 31 of  652 with time 6.40386915207\n",
      "loop 32 of  652 with time 6.40505886078\n",
      "loop 33 of  652 with time 6.42572689056\n",
      "loop 34 of  652 with time 6.38711500168\n",
      "loop 35 of  652 with time 6.39246106148\n",
      "loop 36 of  652 with time 6.39486002922\n",
      "loop 37 of  652 with time 6.48360991478\n",
      "loop 38 of  652 with time 6.43485188484\n",
      "loop 39 of  652 with time 6.39783096313\n",
      "loop 40 of  652 with time 6.36768913269\n",
      "loop 41 of  652 with time 6.36993503571\n",
      "loop 42 of  652 with time 6.36304593086\n",
      "loop 43 of  652 with time 6.39392209053\n",
      "loop 44 of  652 with time 6.36962008476\n",
      "loop 45 of  652 with time 6.3807079792\n",
      "loop 46 of  652 with time 6.43714690208\n",
      "loop 47 of  652 with time 6.77526402473\n",
      "loop 48 of  652 with time 6.43343400955\n",
      "loop 49 of  652 with time 6.38640499115\n",
      "loop 50 of  652 with time 6.387196064\n",
      "loop 51 of  652 with time 6.42520213127\n",
      "loop 52 of  652 with time 6.40433096886\n",
      "loop 53 of  652 with time 6.44688987732\n",
      "loop 54 of  652 with time 6.40351200104\n",
      "loop 55 of  652 with time 6.38645410538\n",
      "loop 56 of  652 with time 6.37300682068\n",
      "loop 57 of  652 with time 6.46027398109\n",
      "loop 58 of  652 with time 6.43521499634\n",
      "loop 59 of  652 with time 6.40765500069\n",
      "loop 60 of  652 with time 6.41218686104\n",
      "loop 61 of  652 with time 6.39779782295\n",
      "loop 62 of  652 with time 6.42831611633\n",
      "loop 63 of  652 with time 6.41005396843\n",
      "loop 64 of  652 with time 6.38473200798\n",
      "loop 65 of  652 with time 6.39059400558\n",
      "loop 66 of  652 with time 6.4342520237\n",
      "loop 67 of  652 with time 6.46118092537\n",
      "loop 68 of  652 with time 6.51437711716\n",
      "loop 69 of  652 with time 6.47723984718\n",
      "loop 70 of  652 with time 6.44976997375\n",
      "loop 71 of  652 with time 6.49680280685\n",
      "loop 72 of  652 with time 6.42825603485\n",
      "loop 73 of  652 with time 6.38928985596\n",
      "loop 74 of  652 with time 6.567497015\n",
      "loop 75 of  652 with time 6.42693281174\n",
      "loop 76 of  652 with time 6.40135002136\n",
      "loop 77 of  652 with time 6.41873383522\n",
      "loop 78 of  652 with time 6.41761803627\n",
      "loop 79 of  652 with time 6.40467810631\n",
      "loop 80 of  652 with time 6.46351385117\n",
      "loop 81 of  652 with time 6.41171503067\n",
      "loop 82 of  652 with time 6.47595906258\n",
      "loop 83 of  652 with time 6.45222187042\n",
      "loop 84 of  652 with time 6.42132401466\n",
      "loop 85 of  652 with time 6.39118909836\n",
      "loop 86 of  652 with time 6.37591791153\n",
      "loop 87 of  652 with time 6.3941860199\n",
      "loop 88 of  652 with time 6.43168306351\n",
      "loop 89 of  652 with time 6.42196393013\n",
      "loop 90 of  652 with time 6.38049387932\n",
      "loop 91 of  652 with time 6.41745996475\n",
      "loop 92 of  652 with time 6.40094709396\n",
      "loop 93 of  652 with time 6.40216898918\n",
      "loop 94 of  652 with time 6.38291406631\n",
      "loop 95 of  652 with time 6.41599488258\n",
      "loop 96 of  652 with time 6.39379906654\n",
      "loop 97 of  652 with time 6.39947295189\n",
      "loop 98 of  652 with time 6.37594199181\n",
      "loop 99 of  652 with time 6.40320086479\n",
      "loop 100 of  652 with time 6.37831497192\n",
      "loop 101 of  652 with time 6.40182805061\n",
      "loop 102 of  652 with time 6.38067603111\n",
      "loop 103 of  652 with time 6.44300103188\n",
      "loop 104 of  652 with time 6.40888094902\n",
      "loop 105 of  652 with time 6.40206384659\n",
      "loop 106 of  652 with time 6.40234780312\n",
      "loop 107 of  652 with time 6.40253686905\n",
      "loop 108 of  652 with time 6.40450310707\n",
      "loop 109 of  652 with time 6.39960885048\n",
      "loop 110 of  652 with time 6.38544607162\n",
      "loop 111 of  652 with time 6.39857077599\n",
      "loop 112 of  652 with time 6.44144701958\n",
      "loop 113 of  652 with time 6.38830590248\n",
      "loop 114 of  652 with time 6.46788215637\n",
      "loop 115 of  652 with time 6.40152406693\n",
      "loop 116 of  652 with time 6.40126490593\n",
      "loop 117 of  652 with time 6.38791918755\n",
      "loop 118 of  652 with time 6.3906788826\n",
      "loop 119 of  652 with time 6.38487386703\n",
      "loop 120 of  652 with time 6.41461181641\n",
      "loop 121 of  652 with time 6.39772987366\n",
      "loop 122 of  652 with time 6.38826394081\n",
      "loop 123 of  652 with time 6.39953279495\n",
      "loop 124 of  652 with time 6.43880105019\n",
      "loop 125 of  652 with time 6.42955684662\n",
      "loop 126 of  652 with time 6.38567495346\n",
      "loop 127 of  652 with time 6.41420102119\n",
      "loop 128 of  652 with time 6.42113518715\n",
      "loop 129 of  652 with time 6.46010899544\n",
      "loop 130 of  652 with time 6.39580702782\n",
      "loop 131 of  652 with time 6.38113689423\n",
      "loop 132 of  652 with time 6.39249420166\n",
      "loop 133 of  652 with time 6.40328478813\n",
      "loop 134 of  652 with time 6.37714600563\n",
      "loop 135 of  652 with time 6.38488698006\n",
      "loop 136 of  652 with time 6.3748459816\n",
      "loop 137 of  652 with time 6.39122009277\n",
      "loop 138 of  652 with time 6.38965201378\n",
      "loop 139 of  652 with time 6.46302008629\n",
      "loop 140 of  652 with time 6.41718101501\n",
      "loop 141 of  652 with time 6.41304397583\n",
      "loop 142 of  652 with time 6.40070986748\n",
      "loop 143 of  652 with time 6.38584399223\n",
      "loop 144 of  652 with time 6.43626213074\n",
      "loop 145 of  652 with time 6.39015603065\n",
      "loop 146 of  652 with time 6.37646102905\n",
      "loop 147 of  652 with time 6.38418412209\n",
      "loop 148 of  652 with time 6.45003390312\n",
      "loop 149 of  652 with time 6.42990803719\n",
      "loop 150 of  652 with time 6.39115190506\n",
      "loop 151 of  652 with time 6.42610192299\n",
      "loop 152 of  652 with time 6.3639998436\n",
      "loop 153 of  652 with time 6.37449097633\n",
      "loop 154 of  652 with time 6.36436104774\n",
      "loop 155 of  652 with time 6.40128612518\n",
      "loop 156 of  652 with time 6.38537693024\n",
      "loop 157 of  652 with time 6.37745118141\n",
      "loop 158 of  652 with time 6.40338802338\n",
      "loop 159 of  652 with time 6.40164399147\n",
      "loop 160 of  652 with time 6.41334986687\n",
      "loop 161 of  652 with time 6.42233610153\n",
      "loop 162 of  652 with time 6.48141002655\n",
      "loop 163 of  652 with time 6.39994692802\n",
      "loop 164 of  652 with time 6.39580893517\n",
      "loop 165 of  652 with time 6.40162110329\n",
      "loop 166 of  652 with time 6.40762019157\n",
      "loop 167 of  652 with time 6.39815282822\n",
      "loop 168 of  652 with time 6.39121794701\n",
      "loop 169 of  652 with time 6.42458200455\n",
      "loop 170 of  652 with time 6.43881392479\n",
      "loop 171 of  652 with time 6.41107201576\n",
      "loop 172 of  652 with time 6.43761396408\n",
      "loop 173 of  652 with time 6.44734597206\n",
      "loop 174 of  652 with time 6.66873717308\n",
      "loop 175 of  652 with time 6.83290314674\n",
      "loop 176 of  652 with time 6.58663201332\n",
      "loop 177 of  652 with time 6.35620594025\n",
      "loop 178 of  652 with time 6.32819986343\n",
      "loop 179 of  652 with time 6.32453894615\n",
      "loop 180 of  652 with time 6.39955997467\n",
      "loop 181 of  652 with time 6.3355050087\n",
      "loop 182 of  652 with time 6.34852981567\n",
      "loop 183 of  652 with time 6.38283491135\n",
      "loop 184 of  652 with time 6.37308597565\n",
      "loop 185 of  652 with time 6.3318939209\n",
      "loop 186 of  652 with time 6.36562991142\n",
      "loop 187 of  652 with time 6.32203793526\n",
      "loop 188 of  652 with time 6.34790301323\n",
      "loop 189 of  652 with time 6.35232400894\n",
      "loop 190 of  652 with time 6.33943510056\n",
      "loop 191 of  652 with time 6.36469483376\n",
      "loop 192 of  652 with time 6.38808202744\n",
      "loop 193 of  652 with time 6.37777805328\n",
      "loop 194 of  652 with time 6.35561418533\n",
      "loop 195 of  652 with time 6.36327195168\n",
      "loop 196 of  652 with time 6.35320186615\n",
      "loop 197 of  652 with time 6.35484600067\n",
      "loop 198 of  652 with time 6.38223814964\n",
      "loop 199 of  652 with time 6.33229112625\n",
      "loop 200 of  652 with time 6.37495088577\n",
      "loop 201 of  652 with time 6.34438610077\n",
      "loop 202 of  652 with time 6.33296298981\n",
      "loop 203 of  652 with time 6.33835697174\n",
      "loop 204 of  652 with time 6.4520368576\n",
      "loop 205 of  652 with time 6.54339289665\n",
      "loop 206 of  652 with time 7.04331803322\n",
      "loop 207 of  652 with time 6.33803796768\n",
      "loop 208 of  652 with time 6.35036683083\n",
      "loop 209 of  652 with time 6.32285904884\n",
      "loop 210 of  652 with time 6.36477303505\n",
      "loop 211 of  652 with time 6.33322000504\n",
      "loop 212 of  652 with time 6.3244330883\n",
      "loop 213 of  652 with time 6.33178091049\n",
      "loop 214 of  652 with time 6.33870887756\n",
      "loop 215 of  652 with time 6.35678482056\n",
      "loop 216 of  652 with time 6.33494901657\n",
      "loop 217 of  652 with time 6.33416390419\n",
      "loop 218 of  652 with time 6.34072804451\n",
      "loop 219 of  652 with time 6.35024905205\n",
      "loop 220 of  652 with time 6.33935213089\n",
      "loop 221 of  652 with time 6.35135102272\n",
      "loop 222 of  652 with time 6.34957098961\n",
      "loop 223 of  652 with time 6.34983086586\n",
      "loop 224 of  652 with time 6.33338689804\n",
      "loop 225 of  652 with time 6.35099101067\n",
      "loop 226 of  652 with time 6.43991804123\n",
      "loop 227 of  652 with time 6.38421201706\n",
      "loop 228 of  652 with time 6.37907099724\n",
      "loop 229 of  652 with time 6.33155083656\n",
      "loop 230 of  652 with time 6.34021997452\n",
      "loop 231 of  652 with time 6.34599614143\n",
      "loop 232 of  652 with time 6.35723400116\n",
      "loop 233 of  652 with time 6.32206320763\n",
      "loop 234 of  652 with time 6.32245802879\n",
      "loop 235 of  652 with time 6.32760095596\n",
      "loop 236 of  652 with time 6.38440918922\n",
      "loop 237 of  652 with time 6.43939399719\n",
      "loop 238 of  652 with time 6.35004401207\n",
      "loop 239 of  652 with time 6.34325814247\n",
      "loop 240 of  652 with time 6.3215379715\n",
      "loop 241 of  652 with time 6.32532906532\n",
      "loop 242 of  652 with time 6.32501602173\n",
      "loop 243 of  652 with time 6.33632993698\n",
      "loop 244 of  652 with time 6.32750892639\n",
      "loop 245 of  652 with time 6.36213588715\n",
      "loop 246 of  652 with time 6.31472992897\n",
      "loop 247 of  652 with time 6.32520389557\n",
      "loop 248 of  652 with time 6.43714618683\n",
      "loop 249 of  652 with time 6.33865404129\n",
      "loop 250 of  652 with time 6.33383488655\n",
      "loop 251 of  652 with time 6.32903599739\n",
      "loop 252 of  652 with time 6.30378699303\n",
      "loop 253 of  652 with time 6.29924893379\n",
      "loop 254 of  652 with time 6.29321193695\n",
      "loop 255 of  652 with time 6.29728579521\n",
      "loop 256 of  652 with time 6.29992389679\n",
      "loop 257 of  652 with time 6.2900121212\n",
      "loop 258 of  652 with time 6.33368206024\n",
      "loop 259 of  652 with time 6.29826498032\n",
      "loop 260 of  652 with time 6.29747796059\n",
      "loop 261 of  652 with time 6.30146503448\n",
      "loop 262 of  652 with time 6.30805706978\n",
      "loop 263 of  652 with time 6.29771208763\n",
      "loop 264 of  652 with time 6.29991793633\n",
      "loop 265 of  652 with time 6.29474306107\n",
      "loop 266 of  652 with time 6.28824806213\n",
      "loop 267 of  652 with time 6.29108190536\n",
      "loop 268 of  652 with time 6.29691982269\n",
      "loop 269 of  652 with time 6.34721302986\n",
      "loop 270 of  652 with time 6.32840013504\n",
      "loop 271 of  652 with time 6.39681196213\n",
      "loop 272 of  652 with time 6.30766701698\n",
      "loop 273 of  652 with time 6.2930150032\n",
      "loop 274 of  652 with time 6.301831007\n",
      "loop 275 of  652 with time 6.29017090797\n",
      "loop 276 of  652 with time 6.29219913483\n",
      "loop 277 of  652 with time 6.2915699482\n",
      "loop 278 of  652 with time 6.29260206223\n",
      "loop 279 of  652 with time 6.29182314873\n",
      "loop 280 of  652 with time 6.31694889069\n",
      "loop 281 of  652 with time 6.29811191559\n",
      "loop 282 of  652 with time 6.29035902023\n",
      "loop 283 of  652 with time 6.29646992683\n",
      "loop 284 of  652 with time 6.29916906357\n",
      "loop 285 of  652 with time 6.29218101501\n",
      "loop 286 of  652 with time 6.32814002037\n",
      "loop 287 of  652 with time 6.28726911545\n",
      "loop 288 of  652 with time 6.29699802399\n",
      "loop 289 of  652 with time 6.29881191254\n",
      "loop 290 of  652 with time 6.30251693726\n",
      "loop 291 of  652 with time 6.37176299095\n",
      "loop 292 of  652 with time 6.33431100845\n",
      "loop 293 of  652 with time 6.29333019257\n",
      "loop 294 of  652 with time 6.32695698738\n",
      "loop 295 of  652 with time 6.29442191124\n",
      "loop 296 of  652 with time 6.2959048748\n",
      "loop 297 of  652 with time 6.29508090019\n",
      "loop 298 of  652 with time 6.29645586014\n",
      "loop 299 of  652 with time 6.29395008087\n",
      "loop 300 of  652 with time 6.33091402054\n",
      "loop 301 of  652 with time 6.33584594727\n",
      "loop 302 of  652 with time 6.50718688965\n",
      "loop 303 of  652 with time 6.40115094185\n",
      "loop 304 of  652 with time 6.56548404694\n",
      "loop 305 of  652 with time 6.82647395134\n",
      "loop 306 of  652 with time 6.4289162159\n",
      "loop 307 of  652 with time 6.34335398674\n",
      "loop 308 of  652 with time 6.54698204994\n",
      "loop 309 of  652 with time 6.37350797653\n",
      "loop 310 of  652 with time 6.40600514412\n",
      "loop 311 of  652 with time 6.36554598808\n",
      "loop 312 of  652 with time 6.47191596031\n",
      "loop 313 of  652 with time 6.64384007454\n",
      "loop 314 of  652 with time 6.37456703186\n",
      "loop 315 of  652 with time 6.35062098503\n",
      "loop 316 of  652 with time 6.3490319252\n",
      "loop 317 of  652 with time 6.36451196671\n",
      "loop 318 of  652 with time 6.39464592934\n",
      "loop 319 of  652 with time 6.34505105019\n",
      "loop 320 of  652 with time 6.37309408188\n",
      "loop 321 of  652 with time 6.350867033\n",
      "loop 322 of  652 with time 6.40318799019\n",
      "loop 323 of  652 with time 6.35754704475\n",
      "loop 324 of  652 with time 6.36667394638\n",
      "loop 325 of  652 with time 6.38120794296\n",
      "loop 326 of  652 with time 6.4043738842\n",
      "loop 327 of  652 with time 6.38042998314\n",
      "loop 328 of  652 with time 6.3892390728\n",
      "loop 329 of  652 with time 6.37144494057\n",
      "loop 330 of  652 with time 6.36050510406\n",
      "loop 331 of  652 with time 6.39481401443\n",
      "loop 332 of  652 with time 6.38203787804\n",
      "loop 333 of  652 with time 6.40343403816\n",
      "loop 334 of  652 with time 6.38929891586\n",
      "loop 335 of  652 with time 6.62957000732\n",
      "loop 336 of  652 with time 6.37959599495\n",
      "loop 337 of  652 with time 6.35008716583\n",
      "loop 338 of  652 with time 6.34673905373\n",
      "loop 339 of  652 with time 6.40794205666\n",
      "loop 340 of  652 with time 6.37708592415\n",
      "loop 341 of  652 with time 6.39303207397\n",
      "loop 342 of  652 with time 6.36174082756\n",
      "loop 343 of  652 with time 6.35670089722\n",
      "loop 344 of  652 with time 6.39100289345\n",
      "loop 345 of  652 with time 6.3680357933\n",
      "loop 346 of  652 with time 6.40061116219\n",
      "loop 347 of  652 with time 6.37029290199\n",
      "loop 348 of  652 with time 6.35765504837\n",
      "loop 349 of  652 with time 6.35724687576\n",
      "loop 350 of  652 with time 6.37576699257\n",
      "loop 351 of  652 with time 6.36697006226\n",
      "loop 352 of  652 with time 6.37394595146\n",
      "loop 353 of  652 with time 6.3772611618\n",
      "loop 354 of  652 with time 6.38053607941\n",
      "loop 355 of  652 with time 6.39543509483\n",
      "loop 356 of  652 with time 6.44326496124\n",
      "loop 357 of  652 with time 6.40577888489\n",
      "loop 358 of  652 with time 6.36965608597\n",
      "loop 359 of  652 with time 6.36995196342\n",
      "loop 360 of  652 with time 6.42273402214\n",
      "loop 361 of  652 with time 6.36520004272\n",
      "loop 362 of  652 with time 6.37766003609\n",
      "loop 363 of  652 with time 6.38125920296\n",
      "loop 364 of  652 with time 6.39270687103\n",
      "loop 365 of  652 with time 6.44000005722\n",
      "loop 366 of  652 with time 6.39259982109\n",
      "loop 367 of  652 with time 6.36917710304\n",
      "loop 368 of  652 with time 6.38847398758\n",
      "loop 369 of  652 with time 6.38098406792\n",
      "loop 370 of  652 with time 6.36472797394\n",
      "loop 371 of  652 with time 6.37656998634\n",
      "loop 372 of  652 with time 6.38015413284\n",
      "loop 373 of  652 with time 6.37098383904\n",
      "loop 374 of  652 with time 6.38560700417\n",
      "loop 375 of  652 with time 6.36945509911\n",
      "loop 376 of  652 with time 6.38426780701\n",
      "loop 377 of  652 with time 6.36838197708\n",
      "loop 378 of  652 with time 6.37527894974\n",
      "loop 379 of  652 with time 6.36277294159\n",
      "loop 380 of  652 with time 6.37906980515\n",
      "loop 381 of  652 with time 6.37002897263\n",
      "loop 382 of  652 with time 6.39181423187\n",
      "loop 383 of  652 with time 6.385379076\n",
      "loop 384 of  652 with time 6.39283919334\n",
      "loop 385 of  652 with time 6.38076496124\n",
      "loop 386 of  652 with time 6.38487887383\n",
      "loop 387 of  652 with time 6.54114603996\n",
      "loop 388 of  652 with time 6.39955186844\n",
      "loop 389 of  652 with time 6.38245296478\n",
      "loop 390 of  652 with time 6.39983510971\n",
      "loop 391 of  652 with time 6.37262701988\n",
      "loop 392 of  652 with time 6.38144803047\n",
      "loop 393 of  652 with time 6.36319613457\n",
      "loop 394 of  652 with time 6.3705060482\n",
      "loop 395 of  652 with time 6.36728715897\n",
      "loop 396 of  652 with time 6.42645001411\n",
      "loop 397 of  652 with time 6.4035859108\n",
      "loop 398 of  652 with time 6.41121816635\n",
      "loop 399 of  652 with time 6.39207291603\n",
      "loop 400 of  652 with time 6.54573607445\n",
      "loop 401 of  652 with time 6.66274499893\n",
      "loop 402 of  652 with time 6.51054096222\n",
      "loop 403 of  652 with time 6.34213685989\n",
      "loop 404 of  652 with time 6.37590694427\n",
      "loop 405 of  652 with time 6.34272098541\n",
      "loop 406 of  652 with time 6.34731483459\n",
      "loop 407 of  652 with time 6.35294103622\n",
      "loop 408 of  652 with time 6.61748695374\n",
      "loop 409 of  652 with time 6.3807489872\n",
      "loop 410 of  652 with time 6.36823105812\n",
      "loop 411 of  652 with time 6.3293299675\n",
      "loop 412 of  652 with time 6.32820415497\n",
      "loop 413 of  652 with time 6.33191680908\n",
      "loop 414 of  652 with time 6.34924888611\n",
      "loop 415 of  652 with time 6.3598818779\n",
      "loop 416 of  652 with time 6.35753202438\n",
      "loop 417 of  652 with time 6.34846520424\n",
      "loop 418 of  652 with time 6.68587183952\n",
      "loop 419 of  652 with time 6.3893020153\n",
      "loop 420 of  652 with time 6.39557313919\n",
      "loop 421 of  652 with time 6.34047198296\n",
      "loop 422 of  652 with time 6.32585883141\n",
      "loop 423 of  652 with time 6.32380890846\n",
      "loop 424 of  652 with time 6.3627140522\n",
      "loop 425 of  652 with time 6.32709503174\n",
      "loop 426 of  652 with time 6.37280511856\n",
      "loop 427 of  652 with time 6.33523893356\n",
      "loop 428 of  652 with time 6.40269303322\n",
      "loop 429 of  652 with time 6.33907794952\n",
      "loop 430 of  652 with time 6.36364793777\n",
      "loop 431 of  652 with time 6.32516717911\n",
      "loop 432 of  652 with time 6.42267394066\n",
      "loop 433 of  652 with time 6.39410710335\n",
      "loop 434 of  652 with time 6.40396118164\n",
      "loop 435 of  652 with time 6.36822509766\n",
      "loop 436 of  652 with time 6.38153791428\n",
      "loop 437 of  652 with time 6.33090400696\n",
      "loop 438 of  652 with time 6.35280299187\n",
      "loop 439 of  652 with time 6.31865906715\n",
      "loop 440 of  652 with time 6.39590907097\n",
      "loop 441 of  652 with time 6.33153486252\n",
      "loop 442 of  652 with time 6.37297701836\n",
      "loop 443 of  652 with time 6.33973312378\n",
      "loop 444 of  652 with time 6.36454892159\n",
      "loop 445 of  652 with time 6.33057904243\n",
      "loop 446 of  652 with time 6.35464382172\n",
      "loop 447 of  652 with time 6.33615899086\n",
      "loop 448 of  652 with time 6.38048911095\n",
      "loop 449 of  652 with time 6.3466398716\n",
      "loop 450 of  652 with time 6.37653303146\n",
      "loop 451 of  652 with time 6.35544419289\n",
      "loop 452 of  652 with time 6.37047410011\n",
      "loop 453 of  652 with time 6.33782911301\n",
      "loop 454 of  652 with time 6.39644789696\n",
      "loop 455 of  652 with time 6.39705991745\n",
      "loop 456 of  652 with time 6.35464000702\n",
      "loop 457 of  652 with time 6.37340307236\n",
      "loop 458 of  652 with time 6.34394693375\n",
      "loop 459 of  652 with time 6.37295913696\n",
      "loop 460 of  652 with time 6.3444621563\n",
      "loop 461 of  652 with time 6.35821795464\n",
      "loop 462 of  652 with time 6.34715199471\n",
      "loop 463 of  652 with time 6.34590816498\n",
      "loop 464 of  652 with time 6.33177685738\n",
      "loop 465 of  652 with time 6.36429691315\n",
      "loop 466 of  652 with time 6.35821294785\n",
      "loop 467 of  652 with time 6.36094403267\n",
      "loop 468 of  652 with time 6.33157896996\n",
      "loop 469 of  652 with time 6.37173104286\n",
      "loop 470 of  652 with time 6.32893800735\n",
      "loop 471 of  652 with time 6.35795593262\n",
      "loop 472 of  652 with time 6.33008599281\n",
      "loop 473 of  652 with time 6.38586902618\n",
      "loop 474 of  652 with time 6.70815300941\n",
      "loop 475 of  652 with time 6.39558196068\n",
      "loop 476 of  652 with time 6.36576509476\n",
      "loop 477 of  652 with time 6.33572888374\n",
      "loop 478 of  652 with time 6.37577080727\n",
      "loop 479 of  652 with time 6.32619190216\n",
      "loop 480 of  652 with time 6.3245241642\n",
      "loop 481 of  652 with time 6.34907698631\n",
      "loop 482 of  652 with time 6.34466290474\n",
      "loop 483 of  652 with time 6.32082009315\n",
      "loop 484 of  652 with time 6.31872701645\n",
      "loop 485 of  652 with time 6.3672349453\n",
      "loop 486 of  652 with time 6.32049608231\n",
      "loop 487 of  652 with time 6.32204699516\n",
      "loop 488 of  652 with time 6.3171889782\n",
      "loop 489 of  652 with time 6.37309384346\n",
      "loop 490 of  652 with time 6.33667111397\n",
      "loop 491 of  652 with time 6.3192858696\n",
      "loop 492 of  652 with time 6.31209492683\n",
      "loop 493 of  652 with time 6.34834218025\n",
      "loop 494 of  652 with time 6.31331300735\n",
      "loop 495 of  652 with time 6.35669994354\n",
      "loop 496 of  652 with time 6.34983801842\n",
      "loop 497 of  652 with time 6.35272288322\n",
      "loop 498 of  652 with time 6.38147497177\n",
      "loop 499 of  652 with time 6.35314702988\n",
      "loop 500 of  652 with time 6.35621404648\n",
      "loop 501 of  652 with time 6.35587787628\n",
      "loop 502 of  652 with time 6.33353710175\n",
      "loop 503 of  652 with time 6.40101909637\n",
      "loop 504 of  652 with time 6.37585091591\n",
      "loop 505 of  652 with time 6.3754799366\n",
      "loop 506 of  652 with time 6.36527395248\n",
      "loop 507 of  652 with time 6.3630399704\n",
      "loop 508 of  652 with time 6.35249996185\n",
      "loop 509 of  652 with time 6.4049539566\n",
      "loop 510 of  652 with time 6.39947795868\n",
      "loop 511 of  652 with time 6.35486292839\n",
      "loop 512 of  652 with time 6.32340717316\n",
      "loop 513 of  652 with time 6.35310816765\n",
      "loop 514 of  652 with time 6.32078194618\n",
      "loop 515 of  652 with time 6.32031393051\n",
      "loop 516 of  652 with time 6.41008901596\n",
      "loop 517 of  652 with time 6.35117602348\n",
      "loop 518 of  652 with time 6.32541394234\n",
      "loop 519 of  652 with time 6.31587290764\n",
      "loop 520 of  652 with time 6.37231397629\n",
      "loop 521 of  652 with time 6.3551030159\n",
      "loop 522 of  652 with time 6.34622907639\n",
      "loop 523 of  652 with time 6.40919399261\n",
      "loop 524 of  652 with time 6.3522298336\n",
      "loop 525 of  652 with time 6.39171886444\n",
      "loop 526 of  652 with time 6.34425497055\n",
      "loop 527 of  652 with time 6.36865282059\n",
      "loop 528 of  652 with time 6.39751505852\n",
      "loop 529 of  652 with time 6.32695698738\n",
      "loop 530 of  652 with time 6.33555078506\n",
      "loop 531 of  652 with time 6.33049893379\n",
      "loop 532 of  652 with time 6.3290438652\n",
      "loop 533 of  652 with time 6.38655900955\n",
      "loop 534 of  652 with time 6.35074806213\n",
      "loop 535 of  652 with time 6.33163499832\n",
      "loop 536 of  652 with time 6.37838196754\n",
      "loop 537 of  652 with time 6.33803486824\n",
      "loop 538 of  652 with time 6.31957101822\n",
      "loop 539 of  652 with time 6.33534002304\n",
      "loop 540 of  652 with time 6.36540293694\n",
      "loop 541 of  652 with time 6.31271696091\n",
      "loop 542 of  652 with time 6.40995502472\n",
      "loop 543 of  652 with time 6.36280798912\n",
      "loop 544 of  652 with time 6.37229204178\n",
      "loop 545 of  652 with time 6.34555101395\n",
      "loop 546 of  652 with time 6.34751915932\n",
      "loop 547 of  652 with time 6.30525016785\n",
      "loop 548 of  652 with time 6.3536169529\n",
      "loop 549 of  652 with time 6.34164500237\n",
      "loop 550 of  652 with time 6.3438668251\n",
      "loop 551 of  652 with time 6.35357689857\n",
      "loop 552 of  652 with time 6.37997603416\n",
      "loop 553 of  652 with time 6.34773802757\n",
      "loop 554 of  652 with time 6.35685992241\n",
      "loop 555 of  652 with time 6.39054989815\n",
      "loop 556 of  652 with time 6.36094999313\n",
      "loop 557 of  652 with time 6.32715201378\n",
      "loop 558 of  652 with time 6.35495209694\n",
      "loop 559 of  652 with time 6.30753898621\n",
      "loop 560 of  652 with time 6.31012296677\n",
      "loop 561 of  652 with time 6.35561704636\n",
      "loop 562 of  652 with time 6.38643598557\n",
      "loop 563 of  652 with time 6.33811688423\n",
      "loop 564 of  652 with time 6.39458084106\n",
      "loop 565 of  652 with time 6.3428838253\n",
      "loop 566 of  652 with time 6.34896087646\n",
      "loop 567 of  652 with time 6.38963294029\n",
      "loop 568 of  652 with time 6.32715201378\n",
      "loop 569 of  652 with time 6.31972384453\n",
      "loop 570 of  652 with time 6.36094713211\n",
      "loop 571 of  652 with time 6.32583999634\n",
      "loop 572 of  652 with time 6.36584210396\n",
      "loop 573 of  652 with time 6.3603579998\n",
      "loop 574 of  652 with time 6.36706590652\n",
      "loop 575 of  652 with time 6.43351602554\n",
      "loop 576 of  652 with time 6.37377905846\n",
      "loop 577 of  652 with time 6.35859704018\n",
      "loop 578 of  652 with time 6.38097596169\n",
      "loop 579 of  652 with time 6.3171620369\n",
      "loop 580 of  652 with time 6.37513995171\n",
      "loop 581 of  652 with time 6.32186722755\n",
      "loop 582 of  652 with time 6.33521795273\n",
      "loop 583 of  652 with time 6.37229800224\n",
      "loop 584 of  652 with time 6.33885002136\n",
      "loop 585 of  652 with time 6.33251404762\n",
      "loop 586 of  652 with time 6.36935806274\n",
      "loop 587 of  652 with time 6.32474923134\n",
      "loop 588 of  652 with time 6.37103009224\n",
      "loop 589 of  652 with time 6.32572102547\n",
      "loop 590 of  652 with time 6.33071613312\n",
      "loop 591 of  652 with time 6.41582489014\n",
      "loop 592 of  652 with time 6.3868060112\n",
      "loop 593 of  652 with time 6.31980109215\n",
      "loop 594 of  652 with time 6.36844086647\n",
      "loop 595 of  652 with time 6.32207202911\n",
      "loop 596 of  652 with time 6.37529611588\n",
      "loop 597 of  652 with time 6.32385611534\n",
      "loop 598 of  652 with time 6.38223195076\n",
      "loop 599 of  652 with time 6.37017393112\n",
      "loop 600 of  652 with time 6.36284899712\n",
      "loop 601 of  652 with time 6.36003613472\n",
      "loop 602 of  652 with time 6.32204508781\n",
      "loop 603 of  652 with time 6.32999396324\n",
      "loop 604 of  652 with time 6.35607481003\n",
      "loop 605 of  652 with time 6.33724188805\n",
      "loop 606 of  652 with time 6.33293199539\n",
      "loop 607 of  652 with time 6.34982585907\n",
      "loop 608 of  652 with time 6.33292484283\n",
      "loop 609 of  652 with time 6.35718107224\n",
      "loop 610 of  652 with time 6.3275911808\n",
      "loop 611 of  652 with time 6.3578851223\n",
      "loop 612 of  652 with time 6.39233398438\n",
      "loop 613 of  652 with time 6.34195494652\n",
      "loop 614 of  652 with time 6.33441400528\n",
      "loop 615 of  652 with time 6.36886382103\n",
      "loop 616 of  652 with time 6.34639000893\n",
      "loop 617 of  652 with time 6.36392116547\n",
      "loop 618 of  652 with time 6.32919001579\n",
      "loop 619 of  652 with time 6.32937383652\n",
      "loop 620 of  652 with time 6.36462712288\n",
      "loop 621 of  652 with time 6.32941198349\n",
      "loop 622 of  652 with time 6.44626498222\n",
      "loop 623 of  652 with time 6.34470105171\n",
      "loop 624 of  652 with time 6.34153199196\n",
      "loop 625 of  652 with time 6.34645199776\n",
      "loop 626 of  652 with time 6.31338810921\n",
      "loop 627 of  652 with time 6.31124901772\n",
      "loop 628 of  652 with time 6.35966897011\n",
      "loop 629 of  652 with time 6.31198096275\n",
      "loop 630 of  652 with time 6.36637020111\n",
      "loop 631 of  652 with time 6.35365796089\n",
      "loop 632 of  652 with time 6.41150999069\n",
      "loop 633 of  652 with time 6.38409399986\n",
      "loop 634 of  652 with time 6.35520911217\n",
      "loop 635 of  652 with time 6.34672307968\n",
      "loop 636 of  652 with time 6.42630791664\n",
      "loop 637 of  652 with time 6.34301400185\n",
      "loop 638 of  652 with time 6.43569993973\n",
      "loop 639 of  652 with time 7.18023490906\n",
      "loop 640 of  652 with time 6.39594221115\n",
      "loop 641 of  652 with time 6.32798790932\n",
      "loop 642 of  652 with time 6.31063985825\n",
      "loop 643 of  652 with time 6.3252260685\n",
      "loop 644 of  652 with time 6.31058621407\n",
      "loop 645 of  652 with time 6.29630684853\n",
      "loop 646 of  652 with time 6.30896091461\n",
      "loop 647 of  652 with time 6.3028318882\n",
      "loop 648 of  652 with time 6.32982587814\n",
      "loop 649 of  652 with time 6.296875\n",
      "loop 650 of  652 with time 6.33817005157\n",
      "loop 651 of  652 with time 6.30574798584\n",
      "Total time =  4169.11618114\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "import time\n",
    "\n",
    "clf = MLPClassifier(solver='sgd', alpha=1e-5, hidden_layer_sizes=(128, 128), random_state=1,warm_start=True,activation ='tanh')\n",
    "    #clf.Layer('Softmax', warning=None, name='output', units=None, weight_decay=None, dropout=None, normalize=None, frozen=False)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "loop_c = 1\n",
    "for image in two_way_image_pairs_with_label:\n",
    "    \n",
    "    t0 = time.time()\n",
    "    output_prob = getFeatures(image)  \n",
    "    X=[]\n",
    "    y=[]\n",
    "    X.append(output_prob)\n",
    "    y.append(image[2][0])\n",
    "    clf.fit(X,y) \n",
    "    \n",
    "    t = time.time()-t0\n",
    "    print \"loop\", loop_c, \"of \", len(two_way_image_pairs_with_label), \"with time \" +  str(t)\n",
    "    loop_c = loop_c + 1\n",
    "    #if (loop_c==40):\n",
    "    #    break;\n",
    "\n",
    "\n",
    "    \n",
    "end = time.time()\n",
    "print \"Total time = \", str(end-start) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.74424169,  0.25575831]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = []\n",
    "X_test.append(getFeatures(two_way_image_pairs_with_label[46]))\n",
    "\n",
    "print two_way_image_pairs_with_label[46][2]\n",
    "\n",
    "clf.predict(X_test)\n",
    "\n",
    "clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop: 1 Actual:  [1, 0]  :: Predicted:  [0]  Probability :  [[ 0.78419088  0.21580912]]\n",
      "Loop: 2 Actual:  [0, 1]  :: Predicted:  [0]  Probability :  [[ 0.8437295  0.1562705]]\n",
      "Loop: 3 Actual:  [1, 0]  :: Predicted:  [0]  Probability :  [[ 0.52889808  0.47110192]]\n",
      "Loop: 4 Actual:  [0, 1]  :: Predicted:  [0]  Probability :  [[ 0.802439  0.197561]]\n",
      "Loop: 5 Actual:  [1, 0]  :: Predicted:  [0]  Probability :  [[ 0.71102175  0.28897825]]\n",
      "Loop: 6 Actual:  [0, 1]  :: Predicted:  [0]  Probability :  [[ 0.67882361  0.32117639]]\n",
      "Loop: 7 Actual:  [0, 1]  :: Predicted:  [0]  Probability :  [[ 0.85385071  0.14614929]]\n",
      "Loop: 8 Actual:  [1, 0]  :: Predicted:  [0]  Probability :  [[ 0.86733553  0.13266447]]\n",
      "Loop: 9 Actual:  [0, 1]  :: Predicted:  [0]  Probability :  [[ 0.82063028  0.17936972]]\n",
      "Loop: 10 Actual:  [1, 0]  :: Predicted:  [0]  Probability :  [[ 0.76021654  0.23978346]]\n",
      "Loop: 11 Actual:  [1, 0]  :: Predicted:  [0]  Probability :  [[ 0.94128328  0.05871672]]\n",
      "Loop: 12 Actual:  [0, 1]  :: Predicted:  [0]  Probability :  [[ 0.7421294  0.2578706]]\n",
      "Loop: 13 Actual:  [0, 1]  :: Predicted:  [0]  Probability :  [[ 0.57076427  0.42923573]]\n",
      "Loop: 14 Actual:  [1, 0]  :: Predicted:  [0]  Probability :  [[ 0.8052079  0.1947921]]\n",
      "Loop: 15 Actual:  [0, 1]  :: Predicted:  [0]  Probability :  [[ 0.89903448  0.10096552]]\n",
      "Loop: 16 Actual:  [1, 0]  :: Predicted:  [0]  Probability :  [[ 0.78437352  0.21562648]]\n",
      "Loop: 17 Actual:  [0, 1]  :: Predicted:  [0]  Probability :  [[ 0.82270676  0.17729324]]\n",
      "Loop: 18 Actual:  [1, 0]  :: Predicted:  [0]  Probability :  [[ 0.85724058  0.14275942]]\n",
      "Loop: 19 Actual:  [1, 0]  :: Predicted:  [0]  Probability :  [[ 0.78638207  0.21361793]]\n",
      "Loop: 20 Actual:  [0, 1]  :: Predicted:  [0]  Probability :  [[ 0.67552726  0.32447274]]\n",
      "Loop: 21 Actual:  [1, 0]  :: Predicted:  [0]  Probability :  [[ 0.74711211  0.25288789]]\n",
      "Loop: 22 Actual:  [0, 1]  :: Predicted:  [0]  Probability :  [[ 0.8295462  0.1704538]]\n",
      "Loop: 23 Actual:  [1, 0]  :: Predicted:  [0]  Probability :  [[ 0.74181187  0.25818813]]\n",
      "Loop: 24 Actual:  [0, 1]  :: Predicted:  [0]  Probability :  [[ 0.78041544  0.21958456]]\n",
      "Loop: 25 Actual:  [0, 1]  :: Predicted:  [0]  Probability :  [[ 0.84127746  0.15872254]]\n",
      "Loop: 26 Actual:  [1, 0]  :: Predicted:  [0]  Probability :  [[ 0.81688767  0.18311233]]\n",
      "Loop: 27 Actual:  [0, 1]  :: Predicted:  [0]  Probability :  [[ 0.85939196  0.14060804]]\n",
      "Loop: 28 Actual:  [1, 0]  :: Predicted:  [0]  Probability :  [[ 0.82075257  0.17924743]]\n",
      "Loop: 29 Actual:  [0, 1]  :: Predicted:  [0]  Probability :  [[ 0.84036764  0.15963236]]\n",
      "Loop: 30 Actual:  [1, 0]  :: Predicted:  [0]  Probability :  [[ 0.67548873  0.32451127]]\n",
      "Loop: 31 Actual:  [1, 0]  :: Predicted:  [0]  Probability :  [[ 0.77288523  0.22711477]]\n",
      "Loop: 32 Actual:  [0, 1]  :: Predicted:  [0]  Probability :  [[ 0.80245154  0.19754846]]\n",
      "Loop: 33 Actual:  [1, 0]  :: Predicted:  [0]  Probability :  [[ 0.72664369  0.27335631]]\n",
      "Loop: 34 Actual:  [0, 1]  :: Predicted:  [0]  Probability :  [[ 0.80887232  0.19112768]]\n",
      "Loop: 35 Actual:  [1, 0]  :: Predicted:  [0]  Probability :  [[ 0.61764587  0.38235413]]\n",
      "Loop: 36 Actual:  [0, 1]  :: Predicted:  [0]  Probability :  [[ 0.72612238  0.27387762]]\n",
      "Loop: 37 Actual:  [0, 1]  :: Predicted:  [0]  Probability :  [[ 0.87775561  0.12224439]]\n",
      "Loop: 38 Actual:  [1, 0]  :: Predicted:  [0]  Probability :  [[ 0.82185483  0.17814517]]\n",
      "Loop: 39 Actual:  [1, 0]  :: Predicted:  [0]  Probability :  [[ 0.74233922  0.25766078]]\n",
      "Loop: 40 Actual:  [0, 1]  :: Predicted:  [0]  Probability :  [[ 0.85470516  0.14529484]]\n",
      "Loop: 41 Actual:  [1, 0]  :: Predicted:  [0]  Probability :  [[ 0.83148683  0.16851317]]\n",
      "Loop: 42 Actual:  [0, 1]  :: Predicted:  [0]  Probability :  [[ 0.88295967  0.11704033]]\n",
      "Loop: 43 Actual:  [1, 0]  :: Predicted:  [0]  Probability :  [[ 0.78854179  0.21145821]]\n",
      "Loop: 44 Actual:  [0, 1]  :: Predicted:  [0]  Probability :  [[ 0.89097308  0.10902692]]\n",
      "Loop: 45 Actual:  [1, 0]  :: Predicted:  [0]  Probability :  [[ 0.65363465  0.34636535]]\n",
      "Loop: 46 Actual:  [0, 1]  :: Predicted:  [0]  Probability :  [[ 0.77223196  0.22776804]]\n",
      "Loop: 47 Actual:  [0, 1]  :: Predicted:  [0]  Probability :  [[ 0.74424169  0.25575831]]\n",
      "Loop: 48 Actual:  [1, 0]  :: Predicted:  [0]  Probability :  [[ 0.83548225  0.16451775]]\n",
      "Loop: 49 Actual:  [1, 0]  :: Predicted:  [0]  Probability :  [[ 0.88659807  0.11340193]]\n",
      "Loop: 50 Actual:  [0, 1]  :: Predicted:  [0]  Probability :  [[ 0.89287752  0.10712248]]\n",
      "Loop: 51 Actual:  [1, 0]  :: Predicted:  [0]  Probability :  [[ 0.61862446  0.38137554]]\n",
      "Loop: 52 Actual:  [0, 1]  :: Predicted:  [0]  Probability :  [[ 0.84265701  0.15734299]]\n",
      "Loop: 53 Actual:  [1, 0]  :: Predicted:  [0]  Probability :  [[ 0.64435918  0.35564082]]\n",
      "Loop: 54 Actual:  [0, 1]  :: Predicted:  [0]  Probability :  [[ 0.62018273  0.37981727]]\n",
      "Loop: 55 Actual:  [0, 1]  :: Predicted:  [0]  Probability :  [[ 0.77636797  0.22363203]]\n",
      "Loop: 56 Actual:  [1, 0]  :: Predicted:  [0]  Probability :  [[ 0.73434035  0.26565965]]\n",
      "Loop: 57 Actual:  [1, 0]  :: Predicted:  [0]  Probability :  [[ 0.87949345  0.12050655]]\n",
      "Loop: 58 Actual:  [0, 1]  :: Predicted:  [0]  Probability :  [[ 0.67728133  0.32271867]]\n",
      "Loop: 59 Actual:  [1, 0]  :: Predicted:  [0]  Probability :  [[ 0.57995284  0.42004716]]\n",
      "Loop: 60 Actual:  [0, 1]  :: Predicted:  [0]  Probability :  [[ 0.69541065  0.30458935]]\n",
      "Loop: 61 Actual:  [0, 1]  :: Predicted:  [0]  Probability :  [[ 0.8770097  0.1229903]]\n",
      "Loop: 62 Actual:  [1, 0]  :: Predicted:  [0]  Probability :  [[ 0.77754258  0.22245742]]\n",
      "Loop: 63 Actual:  [1, 0]  :: Predicted:  [0]  Probability :  [[ 0.80763691  0.19236309]]\n",
      "Loop: 64 Actual:  [0, 1]  :: Predicted:  [0]  Probability :  [[ 0.73573924  0.26426076]]\n",
      "Loop: 65 Actual:  [0, 1]  :: Predicted:  [0]  Probability :  [[ 0.92833919  0.07166081]]\n",
      "Loop: 66 Actual:  [1, 0]  :: Predicted:  [0]  Probability :  [[ 0.76705645  0.23294355]]\n",
      "Loop: 67 Actual:  [0, 1]  :: Predicted:  [0]  Probability :  [[ 0.79098756  0.20901244]]\n",
      "Loop: 68 Actual:  [1, 0]  :: Predicted:  [0]  Probability :  [[ 0.70835162  0.29164838]]\n",
      "Loop: 69 Actual:  [1, 0]  :: Predicted:  [0]  Probability :  [[ 0.77422032  0.22577968]]\n",
      "Loop: 70 Actual:  [0, 1]  :: Predicted:  [0]  Probability :  [[ 0.8539458  0.1460542]]\n",
      "Loop: 71 Actual:  [1, 0]  :: Predicted:  [0]  Probability :  [[ 0.69982744  0.30017256]]\n",
      "Loop: 72 Actual:  [0, 1]  :: Predicted:  [0]  Probability :  [[ 0.77859353  0.22140647]]\n",
      "Loop: 73 Actual:  [0, 1]  :: Predicted:  [0]  Probability :  [[ 0.73176484  0.26823516]]\n",
      "Loop: 74 Actual:  [1, 0]  :: Predicted:  [0]  Probability :  [[ 0.8314216  0.1685784]]\n",
      "Loop: 75 Actual:  [1, 0]  :: Predicted:  [0]  Probability :  [[ 0.77848698  0.22151302]]\n",
      "Loop: 76 Actual:  [0, 1]  :: Predicted:  [0]  Probability :  [[ 0.81987158  0.18012842]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-105-b3d8a54159b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimagePair_with_label\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtwo_way_image_pairs_with_label\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetFeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimagePair_with_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-7862c924d961>\u001b[0m in \u001b[0;36mgetFeatures\u001b[0;34m(single_image_pair_with_label)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;31m### perform classification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0moutput_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'diff'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# the output probability vector for the first image in the batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/darshan/caffe/python/caffe/pycaffe.pyc\u001b[0m in \u001b[0;36m_Net_forward\u001b[0;34m(self, blobs, start, end, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0min_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_ind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;31m# Unpack blobs to extract\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loop = 1\n",
    "correct = 0\n",
    "for imagePair_with_label in two_way_image_pairs_with_label:\n",
    "    X_test = []\n",
    "    X_test.append(getFeatures(imagePair_with_label))\n",
    "\n",
    "    p = clf.predict(X_test)\n",
    " \n",
    "    print \"Loop:\", loop, \"Actual: \", imagePair_with_label[2], \" :: Predicted: \", p, \" Probability : \", clf.predict_proba(X_test)     \n",
    "    #if(imagePair_with_label[2][0] == p[0])\n",
    "    #    correct +=1    \n",
    "    loop  += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'tanh',\n",
       " 'alpha': 1e-05,\n",
       " 'batch_size': 'auto',\n",
       " 'beta_1': 0.9,\n",
       " 'beta_2': 0.999,\n",
       " 'early_stopping': False,\n",
       " 'epsilon': 1e-08,\n",
       " 'hidden_layer_sizes': (128, 128),\n",
       " 'learning_rate': 'constant',\n",
       " 'learning_rate_init': 0.001,\n",
       " 'max_iter': 200,\n",
       " 'momentum': 0.9,\n",
       " 'nesterovs_momentum': True,\n",
       " 'power_t': 0.5,\n",
       " 'random_state': 1,\n",
       " 'shuffle': True,\n",
       " 'solver': 'sgd',\n",
       " 'tol': 0.0001,\n",
       " 'validation_fraction': 0.1,\n",
       " 'verbose': False,\n",
       " 'warm_start': True}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.get_params(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2.25514999e-07   2.57264450e-04   9.99742510e-01]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "\n",
    "X,Y = load_iris().data, load_iris().target\n",
    "\n",
    "mlp = MLPClassifier()\n",
    "mlp.fit(X, Y)\n",
    "\n",
    "#print mlp.predict([3.1,  2.5,  8.4,  2.2])\n",
    "print mlp.predict_proba([3.1,  2.5,  8.4,  2.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "y = image[2][0]\n",
    "print y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "description": "Instant recognition with a pre-trained model and a tour of the net interface for visualizing features and parameters layer-by-layer.",
  "example_name": "Image Classification and Filter Visualization",
  "include_in_docs": true,
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "priority": 1
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
